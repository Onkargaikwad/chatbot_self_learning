{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2704da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a5f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('feature selection.txt','r',errors='ignore')\n",
    "raw_doc=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df19869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature selection \\n\\n(first method )\\n\\nunivariant selection types\\n\\n\\n1) Filter Method: The filter method is model-agnostic. \\n                                It selects features based on their individual characteristics without involving any specific machine learning model.\\n                                It relies on statistical measures or predefined criteria to rank or evaluate features independently of the model.\\n\\n\\n2) Wrapper Method: The wrapper method is model-dependent.\\n                   It uses a specific machine learning model as a black box to evaluate the performance of different feature subsets.\\n                   The selection of features is based on how they contribute to improving the model's performance, as assessed by a predefined\\n                   evaluation metric.\\n\\n\\n\\n(second method) \\n\\ntree based model for feature selection\\n\\n1) decision tree.\\n2) random forest.\\n3) gradient boosting model.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8ba375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\onkar\n",
      "[nltk_data]     gaikwad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\onkar\n",
      "[nltk_data]     gaikwad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\onkar\n",
      "[nltk_data]     gaikwad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "raw_doc=raw_doc.lower() #converting entire text to lowercase\n",
    "nltk.download('punkt') #using punkt tokenizer\n",
    "nltk.download('wordnet') #using wordnet dictionary\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "sentences_tokens=nltk.sent_tokenize(raw_doc)\n",
    "word_tokens=nltk.word_tokenize(raw_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4875689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature selection \\n\\n(first method )\\n\\nunivariant selection types\\n\\n\\n1) filter method: the filter method is model-agnostic.',\n",
       " 'it selects features based on their individual characteristics without involving any specific machine learning model.',\n",
       " 'it relies on statistical measures or predefined criteria to rank or evaluate features independently of the model.',\n",
       " '2) wrapper method: the wrapper method is model-dependent.',\n",
       " 'it uses a specific machine learning model as a black box to evaluate the performance of different feature subsets.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf36b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature', 'selection', '(']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f6350",
   "metadata": {},
   "source": [
    "# performing pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59768a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer=nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punc_dict= dict((ord(punct),None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55694d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11cafbb4",
   "metadata": {},
   "source": [
    "# Define Greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85253781",
   "metadata": {},
   "outputs": [],
   "source": [
    "greet_inputs= ('hello','hi','whatsapp','how are you')\n",
    "greet_response=('hi','hey','hey there','there there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e431013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greet_inputs:\n",
    "            return random.choice(greet_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf0d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04d502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c08262cc",
   "metadata": {},
   "source": [
    "# response generate by the bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c96c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f666235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce84b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1_response=''\n",
    "    TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "    tfidf=TfidfVec.fit_transform(sentences_tokens)\n",
    "    vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat=vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf= flat[-2]\n",
    "    if (req_tfidf==0):\n",
    "        robo1_response=robo1_response+\"I'm sorry.Unable to understand you.\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response=robo1_response+sentences_tokens[idx]\n",
    "        return robo1_response\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a33d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello im learning bot. start typing your text after greeting talk to me. for ending convo type bye.\n",
      "hi\n",
      "Botthere there\n",
      "what is filter method?\n",
      "Bot: feature selection \n",
      "\n",
      "(first method )\n",
      "\n",
      "univariant selection types\n",
      "\n",
      "\n",
      "1) filter method: the filter method is model-agnostic.\n"
     ]
    }
   ],
   "source": [
    "flag= True\n",
    "print(\"hello im learning bot. start typing your text after greeting talk to me. for ending convo type bye.\")\n",
    "while(flag==True):\n",
    "    user_response=input()\n",
    "    user_response=user_response.lower()\n",
    "    if (user_response != 'bye'):\n",
    "        if (user_response=='thankyou' or user_response=='thanks'):\n",
    "            flag=False\n",
    "            print('Bot: you are welcome')\n",
    "        else:\n",
    "            if(greet(user_response)!= None):\n",
    "                print('Bot' + greet(user_response))\n",
    "            else:\n",
    "                sentences_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+ nltk.word_tokenize(user_response)\n",
    "                final_words= list(set(word_tokens))\n",
    "                print('Bot: ',end='')\n",
    "                print(response(user_response))\n",
    "                sentences_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print('Bot: Goodbye!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea601f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
